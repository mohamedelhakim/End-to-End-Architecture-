{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2b8e88f2-4644-4604-9b52-66f27c82e820"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers, callbacks\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from keras.layers import *\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score, cohen_kappa_score, roc_auc_score, matthews_corrcoef, average_precision_score\n",
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "from sklearn import model_selection, metrics\n",
        "from sklearn.model_selection import train_test_split,StratifiedKFold,KFold"
      ],
      "id": "2b8e88f2-4644-4604-9b52-66f27c82e820"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UtntINiJpDwJ",
        "outputId": "b18b98f2-ad45-473c-9886-5197b583d6f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "UtntINiJpDwJ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ddc002d-79c6-415d-9f60-184ed2fc5918"
      },
      "outputs": [],
      "source": [
        "rnnamp_model = pd.read_csv('./rnnamp.csv')"
      ],
      "id": "5ddc002d-79c6-415d-9f60-184ed2fc5918"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "832bebde-4b17-4547-a572-84014f3a09ef"
      },
      "outputs": [],
      "source": [],
      "id": "832bebde-4b17-4547-a572-84014f3a09ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a08d555-dd9b-407b-b7dc-24c8c7f18577"
      },
      "outputs": [],
      "source": [
        "m=0\n",
        "clas=['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
        "encode=[]\n",
        "for i in range(len(rnnamp_model)):\n",
        "    st=rnnamp_model['text'][i]\n",
        "    row=[]\n",
        "    ind=1\n",
        "    c=0\n",
        "    if 51>len(st):\n",
        "      m=m+1\n",
        "    for j in range(50):\n",
        "        if j<len(st):\n",
        "          if st[j] != ' ':\n",
        "            index=clas.index(st[j])\n",
        "            l=np.zeros(20)\n",
        "            l[index]=1\n",
        "          else:\n",
        "            c=c+1\n",
        "            continue\n",
        "        else:\n",
        "            l=np.zeros(20)\n",
        "        row.append(l)\n",
        "    l=np.zeros((c,20))\n",
        "    row=np.array(row)\n",
        "    row=np.append(row,l,axis=0)\n",
        "    encode.append(row)\n",
        "encode=np.array(encode)"
      ],
      "id": "8a08d555-dd9b-407b-b7dc-24c8c7f18577"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0747f812-bd03-4e9a-9a16-cac8db174aaf"
      },
      "outputs": [],
      "source": [
        "x_model1=encode\n",
        "y_model1=np.array(rnnamp_model['labels'])\n",
        "x_train1, x_test1, y_train1, y_test1= train_test_split(x_model1,y_model1, test_size=0.2, random_state=0)\n",
        "x_train1, x_val1, y_train1, y_val1= train_test_split(x_train1,y_train1, test_size=0.25, random_state=0)"
      ],
      "id": "0747f812-bd03-4e9a-9a16-cac8db174aaf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQwPwQPik7l2"
      },
      "outputs": [],
      "source": [
        "skfold = StratifiedKFold(n_splits=10, random_state=0, shuffle= True)\n"
      ],
      "id": "JQwPwQPik7l2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b8629e4e-cc73-472f-a66b-81e7e2d28195"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n"
      ],
      "id": "b8629e4e-cc73-472f-a66b-81e7e2d28195"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VsBCih4pfR_"
      },
      "outputs": [],
      "source": [
        "ls ='/content/drive/My Drive/best_model/'"
      ],
      "id": "1VsBCih4pfR_"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3482c7c-98ef-4e4a-91f6-322ac51fa96e",
        "outputId": "dd7e4d3b-0675-444e-e1ad-2dcee697a936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "48/48 [==============================] - ETA: 0s - loss: 0.7692 - accuracy: 0.5114"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r48/48 [==============================] - 4s 35ms/step - loss: 0.7692 - accuracy: 0.5114 - val_loss: 0.7181 - val_accuracy: 0.5527\n",
            "Epoch 2/100\n",
            "48/48 [==============================] - 2s 31ms/step - loss: 0.7080 - accuracy: 0.5708 - val_loss: 0.6902 - val_accuracy: 0.6035\n",
            "Epoch 3/100\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.6912 - accuracy: 0.6040 - val_loss: 0.6874 - val_accuracy: 0.6152\n",
            "Epoch 4/100\n",
            "48/48 [==============================] - 2s 38ms/step - loss: 0.6502 - accuracy: 0.6523 - val_loss: 0.6182 - val_accuracy: 0.6855\n",
            "Epoch 5/100\n",
            "48/48 [==============================] - 2s 33ms/step - loss: 0.6030 - accuracy: 0.7045 - val_loss: 0.5867 - val_accuracy: 0.7051\n",
            "Epoch 6/100\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.5694 - accuracy: 0.7293 - val_loss: 0.5639 - val_accuracy: 0.7441\n",
            "Epoch 7/100\n",
            "48/48 [==============================] - 1s 30ms/step - loss: 0.5172 - accuracy: 0.7834 - val_loss: 0.5424 - val_accuracy: 0.7598\n",
            "Epoch 8/100\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.5046 - accuracy: 0.7795 - val_loss: 0.5247 - val_accuracy: 0.7676\n",
            "Epoch 9/100\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.4361 - accuracy: 0.8271 - val_loss: 0.5486 - val_accuracy: 0.7617\n",
            "Epoch 10/100\n",
            "48/48 [==============================] - 1s 22ms/step - loss: 0.4027 - accuracy: 0.8519 - val_loss: 0.5274 - val_accuracy: 0.7598\n",
            "Epoch 11/100\n",
            "48/48 [==============================] - 2s 32ms/step - loss: 0.3392 - accuracy: 0.8813 - val_loss: 0.5146 - val_accuracy: 0.7832\n",
            "Epoch 12/100\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.2995 - accuracy: 0.8911 - val_loss: 0.5399 - val_accuracy: 0.7754\n",
            "Epoch 13/100\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.2648 - accuracy: 0.9080 - val_loss: 0.5248 - val_accuracy: 0.7676\n",
            "Epoch 14/100\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.2153 - accuracy: 0.9282 - val_loss: 0.6498 - val_accuracy: 0.7559\n",
            "Epoch 15/100\n",
            "48/48 [==============================] - 2s 34ms/step - loss: 0.1768 - accuracy: 0.9374 - val_loss: 0.6348 - val_accuracy: 0.7910\n",
            "Epoch 16/100\n",
            "48/48 [==============================] - 1s 23ms/step - loss: 0.1682 - accuracy: 0.9465 - val_loss: 0.6470 - val_accuracy: 0.7754\n",
            "Epoch 17/100\n",
            "48/48 [==============================] - 1s 25ms/step - loss: 0.1405 - accuracy: 0.9537 - val_loss: 0.8061 - val_accuracy: 0.7754\n",
            "Epoch 18/100\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.1174 - accuracy: 0.9726 - val_loss: 0.8967 - val_accuracy: 0.7832\n",
            "Epoch 19/100\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.0905 - accuracy: 0.9772 - val_loss: 0.5924 - val_accuracy: 0.7832\n",
            "Epoch 20/100\n",
            "48/48 [==============================] - 1s 31ms/step - loss: 0.0839 - accuracy: 0.9804 - val_loss: 0.7713 - val_accuracy: 0.8008\n",
            "Epoch 21/100\n",
            "48/48 [==============================] - 1s 24ms/step - loss: 0.0838 - accuracy: 0.9791 - val_loss: 0.7937 - val_accuracy: 0.7910\n",
            "16/16 [==============================] - 0s 5ms/step\n",
            "fold=  1\n",
            "Accuracy_model = %.3f 80.46875\n"
          ]
        }
      ],
      "source": [
        "\n",
        "scores =[]\n",
        "i=1\n",
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath=ls+'best_model1.h5', monitor='val_accuracy', save_best_only=True,mode='auto')]\n",
        "\n",
        "model1 = Sequential()\n",
        "model1.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same',input_shape=(50,20,1)))\n",
        "model1.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same'))\n",
        "model1.add(Conv2D(64, kernel_size=(7,7),activation='relu',padding='same'))\n",
        "model1.add(Conv2D(64, kernel_size=(5,5),activation='relu',padding='same'))\n",
        "model1.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model1.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model1.add(Flatten())\n",
        "model1.add(tf.keras.layers.Dense(64, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l2=0.001)))\n",
        "model1.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid,kernel_regularizer=tf.keras.regularizers.l2(l2=0.01)))\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model1.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model1.fit(x_train1,y_train1,epochs = 100,batch_size=32,validation_data=(x_val1,y_val1),callbacks=[callback],verbose=1,shuffle= True)\n",
        "y_pred=model1.predict(x_test1)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "print('fold= ',i)\n",
        "acc_model=100*metrics.accuracy_score(y_test1, y_pred)\n",
        "print('Accuracy_model = %.3f' ,acc_model)\n",
        "scores.append([acc_model])\n",
        "\n"
      ],
      "id": "f3482c7c-98ef-4e4a-91f6-322ac51fa96e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oANhNkW1rwFk"
      },
      "outputs": [],
      "source": [],
      "id": "oANhNkW1rwFk"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dc7883d-7fed-4760-aafe-342ae4662b6f",
        "outputId": "9a51f2b6-d340-4586-d194-cbf8c7f8c557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "80/80 [==============================] - 0s 5ms/step\n",
            "HemoPI-1 model datasets\n",
            "deep learning: Accuracy 91.40%\n",
            "deep learning: Precision-Recall 89.17%\n",
            "deep learning: Matthews Coefficient 82.77%\n",
            "deep learning: Cohen Kappa Score 82.75%\n",
            "deep learning: ROC AUC Score 91.43%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.90      0.92      0.91      1198\n",
            "      high 1       0.93      0.91      0.92      1359\n",
            "\n",
            "    accuracy                           0.91      2557\n",
            "   macro avg       0.91      0.91      0.91      2557\n",
            "weighted avg       0.91      0.91      0.91      2557\n",
            "\n",
            "HemoPI-1 validation datasets\n",
            "16/16 [==============================] - 0s 5ms/step\n",
            "deep learning: Accuracy 80.66%\n",
            "deep learning: Precision 83.00%\n",
            "deep learning: Recall 78.95%\n",
            "deep learning: Matthews Coefficient 61.42%\n",
            "deep learning: Cohen Kappa Score 61.35%\n",
            "deep learning: ROC AUC Score 80.73%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.78      0.83      0.80       246\n",
            "      high 1       0.83      0.79      0.81       266\n",
            "\n",
            "    accuracy                           0.81       512\n",
            "   macro avg       0.81      0.81      0.81       512\n",
            "weighted avg       0.81      0.81      0.81       512\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model1 = tf.keras.models.load_model(ls+'rnnamp.h5')\n",
        "y_pred=model1.predict(x_model1)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "\n",
        "cv_preds = y_pred\n",
        "print('HemoPI-1 model datasets')\n",
        "name='deep learning'\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_model1, cv_preds)))\n",
        "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_model1, cv_preds)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_model1, cv_preds)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_model1, cv_preds)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_model1, cv_preds)))\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_model1, cv_preds, target_names=target_names))\n",
        "\n",
        "# Predictions Validation Set\n",
        "print('HemoPI-1 validation datasets')\n",
        "y_pred2=model1.predict(x_test1)\n",
        "y_pred2[y_pred2>0.5]=1\n",
        "y_pred2[y_pred2<0.5]=0\n",
        "cv_preds2 = y_pred2\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test1, cv_preds2)))\n",
        "print(\"%s: Precision %0.2f%%\" % (name, 100*metrics.precision_score(y_test1, cv_preds2)))\n",
        "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test1, cv_preds2)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_test1, cv_preds2)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test1, cv_preds2)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_test1, cv_preds2)))\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_test1, cv_preds2, target_names=target_names))"
      ],
      "id": "0dc7883d-7fed-4760-aafe-342ae4662b6f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dd13c17-5fe9-4671-a078-494822eb4c60"
      },
      "outputs": [],
      "source": [
        "hlppredfuse_model = pd.read_csv('./hlppredfuse.csv')"
      ],
      "id": "1dd13c17-5fe9-4671-a078-494822eb4c60"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6fd0c8a-b26d-44fc-aa1b-4cbebfbb0200"
      },
      "outputs": [],
      "source": [
        "m=0\n",
        "clas=['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
        "encode2=[]\n",
        "for i in range(len(hlppredfuse_model)):\n",
        "    st=hlppredfuse_model['text'][i]\n",
        "    row=[]\n",
        "    ind=1\n",
        "    c=0\n",
        "    for j in range(50):\n",
        "        if j<len(st):\n",
        "          if st[j] != ' ':\n",
        "            index=clas.index(st[j])\n",
        "            l=np.zeros(20)\n",
        "            l[index]=1\n",
        "          else:\n",
        "            c=c+1\n",
        "            continue\n",
        "        else:\n",
        "            l=np.zeros(20)\n",
        "        row.append(l)\n",
        "    l=np.zeros((c,20))\n",
        "    row=np.array(row)\n",
        "    row=np.append(row,l,axis=0)\n",
        "    encode2.append(row)\n",
        "encode2=np.array(encode2)"
      ],
      "id": "a6fd0c8a-b26d-44fc-aa1b-4cbebfbb0200"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f720a90c-7781-4e41-a36f-18ad75b79748"
      },
      "outputs": [],
      "source": [
        "x_model2=encode2\n",
        "y_model2=np.array(hlppredfuse_model['labels'])\n",
        "x_train2, x_test2, y_train2, y_test2= train_test_split(x_model2,y_model2, test_size=0.2, random_state=0)\n",
        "x_train2, x_val2, y_train2, y_val2 = train_test_split(x_train2,y_train2, test_size=0.25, random_state=0)\n"
      ],
      "id": "f720a90c-7781-4e41-a36f-18ad75b79748"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4b42e77f-b51f-426d-9976-4227b2e9c3b7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a0a6144-88ea-4962-ced0-dc6c0b7766b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "22/22 [==============================] - 1s 14ms/step\n",
            "fold=  1\n",
            "Accuracy_model %0.3f 94.17613636363636\n"
          ]
        }
      ],
      "source": [
        "scores =[]\n",
        "i=1\n",
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath=ls+'best_model2.h5', monitor='val_accuracy',save_best_only=True,mode='auto')]\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same',input_shape=(50,20,1)))\n",
        "model2.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same'))\n",
        "model2.add(Conv2D(64, kernel_size=(7,7),activation='relu',padding='same'))\n",
        "model2.add(Conv2D(64, kernel_size=(5,5),activation='relu',padding='same'))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model2.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model2.add(Flatten())\n",
        "model2.add(tf.keras.layers.Dense(64, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l2=0.001)))\n",
        "model2.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid,kernel_regularizer=tf.keras.regularizers.l2(l2=0.01)))\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model2.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model2.fit(x_train2,y_train2,epochs = 100,batch_size=32,validation_data=(x_val2,y_val2),callbacks=[callback],verbose=0,shuffle= True)\n",
        "y_pred=model2.predict(x_test2)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "print('fold= ',i)\n",
        "acc_model=100*metrics.accuracy_score(y_test2, y_pred)\n",
        "print('Accuracy_model %0.3f' ,100*metrics.accuracy_score(y_test2, y_pred))\n"
      ],
      "id": "4b42e77f-b51f-426d-9976-4227b2e9c3b7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EmAuytIKr8Bj"
      },
      "outputs": [],
      "source": [],
      "id": "EmAuytIKr8Bj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IbIwDXvOGP8"
      },
      "outputs": [],
      "source": [],
      "id": "9IbIwDXvOGP8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cd2b541b-bcb4-4def-ab70-cb6b3c1f5573",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16fc508e-bfaa-4a8d-b67f-945fb5a1bed7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "110/110 [==============================] - 77s 691ms/step\n",
            "HemoPI-2 model datasets\n",
            "deep learning: Accuracy 97.19%\n",
            "deep learning: Precision-Recall 92.98%\n",
            "deep learning: Matthews Coefficient 93.41%\n",
            "deep learning: Cohen Kappa Score 93.38%\n",
            "deep learning: ROC AUC Score 96.26%\n",
            "Sensitivity: 0.9379562043795621\n",
            "Specificity: 0.9872006606110653\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.97      0.99      0.98      2422\n",
            "      high 1       0.97      0.94      0.95      1096\n",
            "\n",
            "    accuracy                           0.97      3518\n",
            "   macro avg       0.97      0.96      0.97      3518\n",
            "weighted avg       0.97      0.97      0.97      3518\n",
            "\n",
            "HemoPI-2 validation datasets\n",
            "22/22 [==============================] - 15s 683ms/step\n",
            "deep learning: Accuracy 94.89%\n",
            "deep learning: Precision-Recall 94.66%\n",
            "deep learning: Matthews Coefficient 87.99%\n",
            "deep learning: Cohen Kappa Score 87.89%\n",
            "deep learning: ROC AUC Score 93.18%\n",
            "deep learning: Recall 88.64%\n",
            "Sensitivity: 0.8863636363636364\n",
            "Specificity: 0.9772727272727273\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.95      0.98      0.96       484\n",
            "      high 1       0.95      0.89      0.92       220\n",
            "\n",
            "    accuracy                           0.95       704\n",
            "   macro avg       0.95      0.93      0.94       704\n",
            "weighted avg       0.95      0.95      0.95       704\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model2 = tf.keras.models.load_model(ls+'hlppredfuse.h5')\n",
        "y_pred=model2.predict(x_model2)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "\n",
        "cv_preds = y_pred\n",
        "print('HemoPI-2 model datasets')\n",
        "name='deep learning'\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_model2, cv_preds)))\n",
        "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_model2, cv_preds)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_model2, cv_preds)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_model2, cv_preds)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_model2, cv_preds)))\n",
        "tn, fp, fn, tp = confusion_matrix(y_model2, cv_preds).ravel()\n",
        "\n",
        "# calculate sensitivity\n",
        "sensitivity = tp / (tp + fn)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_model2, cv_preds, target_names=target_names))\n",
        "\n",
        "# Predictions Validation Set\n",
        "print('HemoPI-2 validation datasets')\n",
        "y_pred2=model2.predict(x_test2)\n",
        "y_pred2[y_pred2>0.5]=1\n",
        "y_pred2[y_pred2<0.5]=0\n",
        "cv_preds2 = y_pred2\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test2, cv_preds2)))\n",
        "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.precision_score(y_test2, cv_preds2)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_test2, cv_preds2)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test2, cv_preds2)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_test2, cv_preds2)))\n",
        "print(\"%s: Recall %0.2f%%\" % (name, 100*metrics.recall_score(y_test2, cv_preds2)))\n",
        "\n",
        "tn, fp, fn, tp = confusion_matrix(y_test2, cv_preds2).ravel()\n",
        "\n",
        "# calculate sensitivity\n",
        "sensitivity = tp / (tp + fn)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_test2, cv_preds2, target_names=target_names))"
      ],
      "id": "cd2b541b-bcb4-4def-ab70-cb6b3c1f5573"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "40a27101-b17d-4cc4-9a2a-dbe9918963db"
      },
      "outputs": [],
      "source": [
        "combined_model = pd.read_csv('./combined.csv')"
      ],
      "id": "40a27101-b17d-4cc4-9a2a-dbe9918963db"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "635ca63c-a37f-4076-8fb9-84be2c07eb80"
      },
      "outputs": [],
      "source": [
        "m=0\n",
        "clas=['A','C','D','E','F','G','H','I','K','L','M','N','P','Q','R','S','T','V','W','Y']\n",
        "encode3=[]\n",
        "for i in range(len(combined_model)):\n",
        "    st=combined_model['text'][i]\n",
        "    row=[]\n",
        "    ind=1\n",
        "    c=0\n",
        "    for j in range(50):\n",
        "        if j<len(st):\n",
        "          if st[j] != ' ':\n",
        "            index=clas.index(st[j])\n",
        "            l=np.zeros(20)\n",
        "            l[index]=1\n",
        "          else:\n",
        "            c=c+1\n",
        "            continue\n",
        "        else:\n",
        "            l=np.zeros(20)\n",
        "        row.append(l)\n",
        "    l=np.zeros((c,20))\n",
        "    row=np.array(row)\n",
        "    row=np.append(row,l,axis=0)\n",
        "    encode3.append(row)\n",
        "encode3=np.array(encode3)"
      ],
      "id": "635ca63c-a37f-4076-8fb9-84be2c07eb80"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9c3290c2-ee7a-41af-aea2-4509bbfdc0ba"
      },
      "outputs": [],
      "source": [
        "x_model3=encode3\n",
        "y_model3=np.array(combined_model['labels'])\n",
        "x_train3, x_test3, y_train3, y_test3 = train_test_split(x_model3,y_model3, test_size=0.2, random_state=0)\n",
        "x_train3, x_val3, y_train3, y_val3 = train_test_split(x_train3,y_train3, test_size=0.25, random_state=0)\n"
      ],
      "id": "9c3290c2-ee7a-41af-aea2-4509bbfdc0ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c72be1f3-ef56-48c3-9fd2-a4e21e164ef0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae51b814-7ef2-4f1e-ffcd-313cb6cee546"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45/45 [==============================] - 0s 5ms/step\n",
            "fold=  1\n",
            "Accuracy_model %0.3f 88.09192200557104\n"
          ]
        }
      ],
      "source": [
        "i=1\n",
        "callback = [tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=10),tf.keras.callbacks.ModelCheckpoint(filepath=ls+'best_model3.h5', monitor='val_accuracy', save_best_only=True,mode='auto')]\n",
        "\n",
        "model3 = Sequential()\n",
        "model3.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same',input_shape=(50,20,1)))\n",
        "model3.add(Conv2D(32, kernel_size=(11, 11),activation='relu',padding='same'))\n",
        "model3.add(Conv2D(64, kernel_size=(7,7),activation='relu',padding='same'))\n",
        "model3.add(Conv2D(64, kernel_size=(5,5),activation='relu',padding='same'))\n",
        "model3.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model3.add(Conv2D(128, kernel_size=(3,3),activation='relu',padding='same'))\n",
        "model3.add(Flatten())\n",
        "model3.add(tf.keras.layers.Dense(64, activation=tf.nn.relu,kernel_regularizer=tf.keras.regularizers.l2(l2=0.001)))\n",
        "model3.add(tf.keras.layers.Dense(1, activation=tf.nn.sigmoid,kernel_regularizer=tf.keras.regularizers.l2(l2=0.01)))\n",
        "optimizer = Adam(learning_rate=0.0001)\n",
        "model3.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "history = model3.fit(x_train3,y_train3,epochs = 100,batch_size=32,validation_data=(x_val3,y_val3),callbacks=[callback],verbose=0,shuffle=True)\n",
        "y_pred=model3.predict(x_test3)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "print('fold= ',i)\n",
        "acc_model=100*metrics.accuracy_score(y_test3, y_pred)\n",
        "print('Accuracy_model %0.3f' ,100*metrics.accuracy_score(y_test3, y_pred))\n"
      ],
      "id": "c72be1f3-ef56-48c3-9fd2-a4e21e164ef0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-8sI0NHrAQM9"
      },
      "outputs": [],
      "source": [],
      "id": "-8sI0NHrAQM9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tHi3OVlXsCZM"
      },
      "outputs": [],
      "source": [],
      "id": "tHi3OVlXsCZM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "589b1886-5f6e-485e-9ae8-35508ec28d92",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e359c44-f54b-4cf6-ce8c-dead40eaf76f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "225/225 [==============================] - 1s 5ms/step\n",
            "HemoPI-3 model datasets\n",
            "deep learning: Accuracy 94.97%\n",
            "deep learning: Precision-Recall 90.96%\n",
            "deep learning: Matthews Coefficient 89.66%\n",
            "deep learning: Cohen Kappa Score 89.66%\n",
            "deep learning: ROC AUC Score 94.80%\n",
            "Sensitivity: 0.9371466577984703\n",
            "Specificity: 0.9587727708533078\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.95      0.96      0.96      4172\n",
            "      high 1       0.94      0.94      0.94      3007\n",
            "\n",
            "    accuracy                           0.95      7179\n",
            "   macro avg       0.95      0.95      0.95      7179\n",
            "weighted avg       0.95      0.95      0.95      7179\n",
            "\n",
            "HemoPI-3 validation datasets\n",
            "45/45 [==============================] - 0s 5ms/step\n",
            "deep learning: Accuracy 87.81%\n",
            "deep learning: Precision-Recall 79.04%\n",
            "deep learning: Matthews Coefficient 74.84%\n",
            "deep learning: Cohen Kappa Score 74.83%\n",
            "deep learning: ROC AUC Score 87.32%\n",
            "Sensitivity: 0.8439597315436241\n",
            "Specificity: 0.9023809523809524\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       low 0       0.89      0.90      0.90       840\n",
            "      high 1       0.86      0.84      0.85       596\n",
            "\n",
            "    accuracy                           0.88      1436\n",
            "   macro avg       0.88      0.87      0.87      1436\n",
            "weighted avg       0.88      0.88      0.88      1436\n",
            "\n"
          ]
        }
      ],
      "source": [
        "model3 = tf.keras.models.load_model(ls+'combined.h5')\n",
        "y_pred=model3.predict(x_model3)\n",
        "y_pred[y_pred>0.5]=1\n",
        "y_pred[y_pred<0.5]=0\n",
        "\n",
        "cv_preds = y_pred\n",
        "print('HemoPI-3 model datasets')\n",
        "name='deep learning'\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_model3, cv_preds)))\n",
        "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_model3, cv_preds)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_model3, cv_preds)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_model3, cv_preds)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_model3, cv_preds)))\n",
        "tn, fp, fn, tp = confusion_matrix(y_model3, cv_preds).ravel()\n",
        "\n",
        "# calculate sensitivity\n",
        "sensitivity = tp / (tp + fn)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_model3, cv_preds, target_names=target_names))\n",
        "\n",
        "# Predictions Validation Set\n",
        "print('HemoPI-3 validation datasets')\n",
        "y_pred2=model3.predict(x_test3)\n",
        "y_pred2[y_pred2>0.5]=1\n",
        "y_pred2[y_pred2<0.5]=0\n",
        "cv_preds2 = y_pred2\n",
        "print(\"%s: Accuracy %0.2f%%\" % (name, 100*metrics.accuracy_score(y_test3, cv_preds2)))\n",
        "print(\"%s: Precision-Recall %0.2f%%\" % (name, 100*metrics.average_precision_score(y_test3, cv_preds2)))\n",
        "print(\"%s: Matthews Coefficient %0.2f%%\" % (name, 100*matthews_corrcoef(y_test3, cv_preds2)))\n",
        "print(\"%s: Cohen Kappa Score %0.2f%%\" % (name, 100*metrics.cohen_kappa_score(y_test3, cv_preds2)))\n",
        "print(\"%s: ROC AUC Score %0.2f%%\" % (name, 100*metrics.roc_auc_score(y_test3, cv_preds2)))\n",
        "tn, fp, fn, tp = confusion_matrix(y_test3, cv_preds2).ravel()\n",
        "\n",
        "# calculate sensitivity\n",
        "sensitivity = tp / (tp + fn)\n",
        "print(\"Sensitivity:\", sensitivity)\n",
        "specificity = tn / (tn + fp)\n",
        "print(\"Specificity:\", specificity)\n",
        "\n",
        "target_names = ['low 0', 'high 1']\n",
        "print(classification_report(y_test3, cv_preds2, target_names=target_names))"
      ],
      "id": "589b1886-5f6e-485e-9ae8-35508ec28d92"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "toc-autonumbering": false,
    "toc-showcode": false,
    "toc-showmarkdowntxt": true,
    "toc-showtags": true
  },
  "nbformat": 4,
  "nbformat_minor": 5
}